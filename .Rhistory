entrenamiento <- subset(datos, ejemplo == TRUE)
pruebas <- subset(datos, ejemplo == FALSE)
modelo <- lm(G3 ~., entrenamiento)
print(summarise(modelo))
print(summary(modelo))
ggplot(residuos, aes(residuos), + geom_histogram(fill = 'blue', alpha = 0.5))
plot(modelo)
predicciones <- predict(modelo, pruebas)
resultados <- cbind(predicciones, pruebas$G3)
head(resultados)
colnames(resultados <- c('prediccion','real'))
resultados <- data.frame(resultados)
colnames(resultados) <- c('prediccion','real')
colnames(resultados) <- c('prediccion','real')
head(resultados)
colnames(resultados) <- c('prediccion','real')
head(resultados)
predicciones <- predict(modelo, pruebas)
resultados <- cbind(predicciones, pruebas$G3)
head(resultados)
colnames(resultados) <- c('prediccion','real')
resultados <- data.frame(resultados)
head(resultados)
min(resultados)
cero <- function(x) {
if(x < 0){
return(0)
}else{
return(x)
}
}
resultados$prediccion <- sapply(resultados$prediccion, cero)
min(resultados)
error <- mean((resultados$real - resultados$prediccion)^2)
error
sse <- sum((resultados$prediccion - resultados$real)^2)
sst <- sum((mean(datos$G3 - resultados$real))^2)
sst <- sum((mean(datos$G3) - resultados$real)^2)
resultado <- 1 - sse/sst
resultado
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
str(datos)
library(ggplot2)
ggplot(datos, aes(Survived)) + geom_bar()
ggplot(datos, aes(Pclass)) + geom_bar(aes(fill = factor(Pclass)))
ggplot(datos, aes(Sex)) + geom_bar(aes(fill = factor(Sex)))
ggplot(datos, aes(Age)) + geom_histogram(bins = 20, alpha = 0.5, fill = 'green')
grafico <- ggplot(datos, aes(Pclass, Age))
grafico <- grafico + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.5))
print(grafico)
install.packages('Amelia')
edad <- function(edad, clase){
salida <- edad
for(i in 1:lenght(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
}
edades <- edad(datos$Age)
edades <- edad(datos$Age, datos$Pclass)
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
install.packages('Amelia')
library(Amelia)
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
edad <- function(edad, clase){
salida <- edad
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
}
edades <- edad(datos$Age, datos$Pclass)
datos$Age <- edades
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
str(datos)
library(ggplot2)
ggplot(datos, aes(Survived)) + geom_bar()
ggplot(datos, aes(Pclass)) + geom_bar(aes(fill = factor(Pclass)))
ggplot(datos, aes(Sex)) + geom_bar(aes(fill = factor(Sex)))
ggplot(datos, aes(Age)) + geom_histogram(bins = 20, alpha = 0.5, fill = 'green')
grafico <- ggplot(datos, aes(Pclass, Age))
grafico <- grafico + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.5))
print(grafico)
install.packages('Amelia')
library(Amelia)
install.packages("Amelia")
install.packages("Amelia")
install.packages('Amelia')
library(Amelia)
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
edad <- function(edad, clase){
salida <- edad
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
}
edades <- edad(datos$Age, datos$Pclass)
datos$Age <- edades
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
str(datos)
library(ggplot2)
ggplot(datos, aes(Survived)) + geom_bar()
ggplot(datos, aes(Pclass)) + geom_bar(aes(fill = factor(Pclass)))
ggplot(datos, aes(Sex)) + geom_bar(aes(fill = factor(Sex)))
ggplot(datos, aes(Age)) + geom_histogram(bins = 20, alpha = 0.5, fill = 'green')
grafico <- ggplot(datos, aes(Pclass, Age))
grafico <- grafico + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.5))
print(grafico)
install.packages('Amelia')
install.packages("Amelia")
library(Amelia)
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
edad <- function(edad, clase){
salida <- edad
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
}
edades <- edad(datos$Age, datos$Pclass)
datos$Age <- edades
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
str(datos)
library(ggplot2)
ggplot(datos, aes(Survived)) + geom_bar()
ggplot(datos, aes(Pclass)) + geom_bar(aes(fill = factor(Pclass)))
ggplot(datos, aes(Sex)) + geom_bar(aes(fill = factor(Sex)))
ggplot(datos, aes(Age)) + geom_histogram(bins = 20, alpha = 0.5, fill = 'green')
grafico <- ggplot(datos, aes(Pclass, Age))
grafico <- grafico + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.5))
print(grafico)
library(Amelia)
edad <- function(edad, clase){
salida <- edad
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
return(salida)
}
}
edades <- edad(datos$Age, datos$Pclass)
datos$Age <- edades
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
# Regresion logistica
datos <- read.csv('Resources/titanic.csv')
head(datos)
str(datos)
library(ggplot2)
ggplot(datos, aes(Survived)) + geom_bar()
ggplot(datos, aes(Pclass)) + geom_bar(aes(fill = factor(Pclass)))
ggplot(datos, aes(Sex)) + geom_bar(aes(fill = factor(Sex)))
ggplot(datos, aes(Age)) + geom_histogram(bins = 20, alpha = 0.5, fill = 'green')
grafico <- ggplot(datos, aes(Pclass, Age))
grafico <- grafico + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.5))
print(grafico)
library(Amelia)
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
edad <- function(edad, clase){
salida <- edad
for(i in 1:length(edad)){
if(is.na(edad[i])){
if(clase[i] == 1){
salida[i] <- 38
} else if(clase[i] == 2){
salida[i] <- 29
} else {
salida[i] <- 23
}
} else {
salida[i] <- edad[i]
}
}
return(salida)
}
edades <- edad(datos$Age, datos$Pclass)
datos$Age <- edades
missmap(datos, main = 'Verificar valores nulos', col = c('red', 'black'))
# part 3
library(dplyr)
head(datos)
datos <- select(datos, -PassengerId, -Name, -Ticket, -Cabin)
head(datos)
datos$Survived = factor(datos$Survived)
datos$Pclass = factor(datos$Pclass)
datos$Parch = factor(datos$Parch)
datos$SibSp = factor(datos$SibSp)
str(datos)
library(caTools)
set.seed(90)
division <- sample.split(datos$Survived, SplitRatio = 0.7)
entrenamiento <- subset(datos, division == TRUE)
pruebas <- subset(datos, division == FALSE)
head(entrenamiento)
modelo <- glm(Survided ~., family = binomial(link = 'logit'), data = entrenamiento)
modelo <- glm(Survided ~ . , family = binomial(link = 'logit'), data = entrenamiento)
modelo <- glm(Survived ~ . , family = binomial(link = 'logit'), data = entrenamiento)
summary(modelo)
predicciones <- predict(modelo, pruebas, type = 'response')
predicciones
head(predicciones)
resultados <- ifelse(predicciones > 0.5, 1, 0)
head(resultados)
error <- mean(resultados != pruebas$Survived)
error
precision <- 1 - error
precision
# k vecinos
install.packages('ISLR')
library(ISLR)
datos <- Caravan
head(datos)
str(datos)
any(is.na(datos))
datos.compra <- datos[, 86]
datos.estandarizados <- scale(datos[, -86])
filas <- 1:1000
head(filas)
pruebas.datos <- datos.estandarizados[filas, ]
pruebas.compra <- datos.compra[filas]
entrenamiento.datos <- datos.estandarizados[-filas, ]
entrenamiento.compra <- datos.compra[-filas]
# parte 2
library(class)
set.seed(90)
prediccion.compra <- knn(entrenamiento.datos, pruebas.datos, entrenamiento.compra, k = 1)
head(prediccion.compra)
# k vecinos
install.packages('ISLR')
library(ISLR)
datos <- Caravan
head(datos)
str(datos)
summary(datos$Purchase)
any(is.na(datos))
datos.compra <- datos[, 86]
datos.estandarizados <- scale(datos[, -86])
filas <- 1:1000
head(filas)
pruebas.datos <- datos.estandarizados[filas, ]
pruebas.compra <- datos.compra[filas]
entrenamiento.datos <- datos.estandarizados[-filas, ]
entrenamiento.compra <- datos.compra[-filas]
# parte 2
library(class)
set.seed(90)
prediccion.compra <- knn(entrenamiento.datos, pruebas.datos, entrenamiento.compra, k = 1)
head(prediccion.compra)
error <- mean(pruebas.compra != prediccion.compra)
error
prediccion.compra <- knn(entrenamiento.datos, pruebas.datos, entrenamiento.compra, k = 5)
head(prediccion.compra)
error <- mean(pruebas.compra != prediccion.compra)
error
preddion.compra <- NULL
errores <- NULL
for(i in 1:20){
set.seed(90)
prediccion.compra <- knn(entrenamiento.datos, pruebas.datos, entrenamiento.compra, k = i)
errores[i] <- mean(pruebas.compra != prediccion.compra)
}
print(errores)
valores.k <- 1:20
tabla.errores <- data.frame(errores, valores.k)
tabla.errores
# arboles de decision
install.packages('rpart')
library(rpart)
datos <- kyphosis
head(datos)
arbol <- rpart(kyphosis, data = datos)
printcp(arbol)
# arboles de decision
install.packages('rpart')
install.packages("rpart")
library(rpart)
datos <- kyphosis
head(datos)
arbol <- rpart(kyphosis, data = datos)
printcp(arbol)
plot(arbol, uniform = TRUE, main = 'Arbol de decision')
text(arbol, use.n = TRUE, all = TRUE)
install.packages('rpart.plot')
library(rpart.plot)
prp(arbol)
# random forest
install.packages('randomForest')
library(randomForest)
modelo <- randomForest(Kyphosis ~ ., data = datos)
print(modelo)
modelo$predicted
# Maquina de vectores de soporte - SVM
library(ISLR)
datos <- iris
str(datos)
install.packages('e1070')
library(e1070)
install.packages('e1071')
library(e1071)
modelo <- svm(Species ~ . , datos = datos)
predicciones <- predict(modelo, datos[1:4])
# Maquina de vectores de soporte - SVM
library(ISLR)
datos <- iris
str(datos)
library(e1071)
modelo <- svm(Species ~ . , datos = datos)
modelo <- svm(Species ~ . , data = datos)
predicciones <- predict(modelo, datos[1:4])
predicciones
tabla <- data.frame(datos, predicciones)
tabla
gc()
# k medias
library(ISLR)
datos <- iris
str(datos)
library(ggplot2)
grafico <- ggplot(datos, aes(Petal.Length, Petal.width, color = 'species'))
grafico <- grafico + geom_point(size = 5)
print(grafico)
grafico <- ggplot(datos, aes(Petal.Length, Petal.Width, color = 'species'))
grafico <- grafico + geom_point(size = 5)
print(grafico)
grafico <- ggplot(datos, aes(Petal.Length, Petal.Width, color = Species))
grafico <- grafico + geom_point(size = 5)
print(grafico)
conjuntos <- kmeans(datos[, 1:4], 3, nstart = 20)
print(connjuntos)
print(conjuntos)
table(conjuntos$cluster, datos$Species)
library(cluster)
clusplot(datos, conjuntos$cluster, color = TRUE, shade = TRUE, labels = 0, lines = 0)
# redes neuronales
install.packages('MASS')
datos <- Boston
library(MASS)
datos <- Boston
any(is.na(datos))
maximo <- apply(datos, 2, max)
maximo
minimo <- apply(datos, 2, min)
minimo
datos.normalizados <- scale(datos, center = minimo, scale = maximo - minimo)
datos.normalizados <- as.data.frame(datos.normalizados)
datos.normalizados <- scale(datos, center = minimo, scale = maximo - minimo)
datos.normalizados <- as.data.frame(datos.normalizados)
datos.normalizados
library(caTools)
division <- sample.split(datos.normalizados$medv, SplitRatio = 0.7)
pruebas <- subset(datos.normalizados, division == FALSE)
head(pruebas)
# parte 2
install.packages('neuronalnet')
# parte 2
install.packages('neuronalnet')
library(neuronalnet)
formula <- medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat
red.neuronal <- neuronalnet(formula, data = entrenamiento, hidden = c(5, 3), linear.output = TRUE)
library(neuronalnet)
# parte 2
install.packages('neuronalnet')
library(neuronalnet)
neuralnet
# parte 2
install.packages('neuralnet')
library(neuralnet)
formula <- medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat
red.neuronal <- neuronalnet(formula, data = entrenamiento, hidden = c(5, 3), linear.output = TRUE)
red.neuronal <- neuralnet(formula, data = entrenamiento, hidden = c(5, 3), linear.output = TRUE)
entrenamiento <- subset(datos.normalizados, division == TRUE)
library(caTools)
division <- sample.split(datos.normalizados$medv, SplitRatio = 0.7)
entrenamiento <- subset(datos.normalizados, division == TRUE)
pruebas <- subset(datos.normalizados, division == FALSE)
head(pruebas)
library(neuralnet)
formula <- medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat
red.neuronal <- neuralnet(formula, data = entrenamiento, hidden = c(5, 3), linear.output = TRUE)
plot(red.neuronal)
predicciones <- compute(red.neuronal, pruebas[1:13])
str(predicciones)
predicciones.correctas <- predicciones$net.result * (max(datos$medv) - min(datos$medv)) + min(datos$med)
pruebas.conertidas <- (pruebas$medv) * (max(datos$medv) - min(datos$medv)) + min(datos$medv)
pruebas.convertidas <- (pruebas$medv) * (max(datos$medv) - min(datos$medv)) + min(datos$medv)
error <- sum((pruebas))
error <- sum((pruebas.convertidas - predicciones.correctas)^2) / nrow(pruebas)
error
errores <- data.frame(pruebas.convertidas, predicciones.correctas)
errores
grafico <- ggplot(errores, aes(x = pruebas.convertidas, y = predicciones.correctas))
grafico <- grafico + geom_point()
print(graficos)
print(grafico)
# redes neuronales
install.packages('MASS')
library(MASS)
datos <- Boston
datos <- Boston
any(is.na(datos))
maximo <- apply(datos, 2, max)
maximo
minimo <- apply(datos, 2, min)
minimo
datos.normalizados <- scale(datos, center = minimo, scale = maximo - minimo)
datos.normalizados <- as.data.frame(datos.normalizados)
datos.normalizados
library(caTools)
division <- sample.split(datos.normalizados$medv, SplitRatio = 0.7)
entrenamiento <- subset(datos.normalizados, division == TRUE)
pruebas <- subset(datos.normalizados, division == FALSE)
head(pruebas)
library(neuralnet)
formula <- medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat
red.neuronal <- neuralnet(formula, data = entrenamiento, hidden = c(5, 3), linear.output = TRUE)
plot(red.neuronal)
predicciones <- compute(red.neuronal, pruebas[1:13])
str(predicciones)
predicciones.correctas <- predicciones$net.result * (max(datos$medv) - min(datos$medv)) + min(datos$med)
pruebas.convertidas <- (pruebas$medv) * (max(datos$medv) - min(datos$medv)) + min(datos$medv)
error <- sum((pruebas.convertidas - predicciones.correctas)^2) / nrow(pruebas)
error
errores <- data.frame(pruebas.convertidas, predicciones.correctas)
errores
library(ggplot2)
grafico <- ggplot(errores, aes(x = pruebas.convertidas, y = predicciones.correctas))
grafico <- grafico + geom_point()
print(grafico)
